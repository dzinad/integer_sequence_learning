{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences count: 113845\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "ids = np.array(test_data['Id'])\n",
    "strs = data['Sequence']\n",
    "test_strs = test_data['Sequence']\n",
    "sequences = []\n",
    "test_sequences = []\n",
    "for line in strs:\n",
    "    sequences.append([int(i) for i in line.split(',')])\n",
    "for line in test_strs:\n",
    "    test_sequences.append([int(i) for i in line.split(',')])\n",
    "\n",
    "total = len(sequences)\n",
    "print('Total sequences count: {0}'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_property_percent(f):\n",
    "    n = 0\n",
    "    for sequence in sequences:\n",
    "        if (f(sequence)):\n",
    "            n += 1\n",
    "    return (n * 100. / total, n)\n",
    "\n",
    "def print_percentage(f):\n",
    "    percent, num = has_property_percent(f)\n",
    "    print('{0}% ({1})'.format(percent, num))\n",
    "    \n",
    "def print_sequences(f):\n",
    "    for sequence in sequences:\n",
    "        if (f(sequence)):\n",
    "            print(sequence, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_percent(condition):\n",
    "    my_dict = {}\n",
    "    for i in range(0, 100):\n",
    "        my_dict[i] = 0\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        sequence = np.array(sequence)\n",
    "        mask = condition(sequence)\n",
    "        percent_of_appr = len(sequence[mask]) * 100. / len(sequence)\n",
    "        key = int(percent_of_appr)\n",
    "        my_dict[key] += 1\n",
    "    return my_dict\n",
    "\n",
    "def plot_dict(d):\n",
    "    x = np.arange(100)\n",
    "    plt.bar(x, list(d.values()), width = [1] * len(x))\n",
    "    labels = []\n",
    "    for i in range(0, len(x)):\n",
    "        if i % 10 == 0:\n",
    "            labels.append(str(i) + '%')\n",
    "        else:\n",
    "            labels.append('')\n",
    "    plt.xticks(x, labels)\n",
    "    plt.ylabel('number of sequences')\n",
    "    plt.show()   \n",
    "    \n",
    "def explore_by_dict(condition):\n",
    "    plot_dict(create_dict_percent(condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01932452018094778% (22)\n"
     ]
    }
   ],
   "source": [
    "# 1. static\n",
    "def is_static(sequence):\n",
    "    return len(np.unique(sequence)) == 1\n",
    "\n",
    "print_percentage(is_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31534103386182966% (359)\n"
     ]
    }
   ],
   "source": [
    "# 12. арифметическая прогрессия\n",
    "def is_arithmetic_progression(sequence):\n",
    "    return len(np.unique(np.diff(sequence))) == 1\n",
    "\n",
    "print_percentage(is_arithmetic_progression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1405419649523475% (160)\n"
     ]
    }
   ],
   "source": [
    "# 13. геометрическая прогрессия\n",
    "def is_geometric_progression(sequence):\n",
    "    if (0 in sequence or len(sequence) < 2):\n",
    "        return False\n",
    "    q = sequence[1] * 1. / sequence[0]\n",
    "    for i in range(2, len(sequence)):\n",
    "        if sequence[i] * 1. / sequence[i - 1] != q:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print_percentage(is_geometric_progression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.562914488998199% (8610)\n"
     ]
    }
   ],
   "source": [
    "# 26. Содержит только однозначные числа\n",
    "def contains_only_digits(sequence):\n",
    "    unique_elements = np.unique(sequence)\n",
    "    if len(unique_elements) > 10:\n",
    "        return False\n",
    "    for x in unique_elements:\n",
    "        if x < 0 or x > 9:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print_percentage(contains_only_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_arithmetic_progression(sequence):\n",
    "    if len(sequence) <= 1:\n",
    "        return None\n",
    "    if is_arithmetic_progression(sequence):\n",
    "        last = len(sequence) - 1\n",
    "        d = sequence[last] - sequence[last - 1]\n",
    "        return sequence[last] + d    \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def handle_geometric_progression(sequence):\n",
    "    if len(sequence) <= 1:\n",
    "        return None\n",
    "    if is_geometric_progression(sequence):\n",
    "        last = len(sequence) - 1\n",
    "        r = round(sequence[last] * sequence[last] // sequence[last - 1])\n",
    "        return r\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "from numpy import linalg as la\n",
    "\n",
    "def handle_linear_recurrence(sequence, order):\n",
    "    if len(sequence) <= 2 * order:\n",
    "        return None\n",
    "    a = []\n",
    "    for i in range(0, order):\n",
    "        a.append(sequence[i:order + i])\n",
    "    b = sequence[order:2*order]\n",
    "    try:\n",
    "        c = la.solve(a, b)\n",
    "    except:\n",
    "        return None\n",
    "    for i in range(order, len(sequence) - order):\n",
    "        if np.dot(c, sequence[i:order + i]) != sequence[order + i]:\n",
    "            return None\n",
    "    return np.dot(c, sequence[-order:])\n",
    "\n",
    "def newton_interpolation(sequence, order):\n",
    "    if (len(sequence) <= order + 1):\n",
    "        return None\n",
    "    h = 1\n",
    "    \n",
    "    #count coeffs\n",
    "    div_diff_old = sequence[:order + 1].copy()\n",
    "    div_diff_new = []\n",
    "    c = [sequence[0]]\n",
    "    for i in range(0, order):\n",
    "        div_diff_new = []\n",
    "        for j in range(0, order - i):\n",
    "            div_diff_new.append(div_diff_old[j + 1] - div_diff_old[j])\n",
    "        div_diff_old = div_diff_new.copy()\n",
    "        c.append(div_diff_new[0] / np.math.factorial(i + 1))\n",
    "    if (c[len(c) - 1] == 0):\n",
    "        return None\n",
    "        \n",
    "    #check other points and predict next if everything is ok\n",
    "    for i in range(order, len(sequence) + 1):\n",
    "        next_point = 0\n",
    "        q = (i + 1 - 1) / h\n",
    "        for j in range(0, len(c)):\n",
    "            mn = 1\n",
    "            for k in range(0, j):\n",
    "                mn *= q - k\n",
    "            next_point += c[j] * mn\n",
    "        if i == len(sequence):\n",
    "            return next_point\n",
    "        if next_point != sequence[i]:\n",
    "            return None\n",
    "        \n",
    "def divide_accurately(numerator, denominator, accuracy):\n",
    "    numerator *= 10 ** (accuracy + 1)\n",
    "    fract = numerator // denominator\n",
    "    digits_after_point = []\n",
    "    while fract > 0:\n",
    "        digits_after_point.append(fract % 10)\n",
    "        fract = fract // 10\n",
    "    for i in range(len(digits_after_point), accuracy + 1):\n",
    "        digits_after_point.append(0)\n",
    "    digits_after_point = np.fliplr([np.array(digits_after_point)])[0]\n",
    "    return digits_after_point\n",
    "        \n",
    "\n",
    "def get_possible_int(sequence):\n",
    "    denominator = 0\n",
    "    mn = 1\n",
    "    eps = 0.000001\n",
    "    for x in sequence:\n",
    "        mn *= 0.1\n",
    "        denominator += mn * x\n",
    "    if np.abs((1 / denominator) - round(1 / denominator)) < eps:\n",
    "        return round(1 / denominator)\n",
    "    return None\n",
    "\n",
    "def handle_decimal_expansion(sequence):\n",
    "    if (len(sequence) <= 2):\n",
    "        return None\n",
    "    if (contains_only_digits(sequence) == False):\n",
    "        return None\n",
    "    possible_int = get_possible_int(sequence)\n",
    "    if possible_int is None:\n",
    "        return None\n",
    "    possible_float = divide_accurately(1, possible_int, len(sequence) + 2)\n",
    "    for i, x in enumerate(sequence):\n",
    "        if x != possible_float[i]:\n",
    "            return None\n",
    "    return possible_float[len(sequence)]\n",
    "\n",
    "def handle_partial_sums(sequence):\n",
    "    if len(sequence) == 0:\n",
    "        return None\n",
    "    initial_sequence = np.hstack((np.array(sequence[0]), np.diff(sequence)))\n",
    "    next_element = apply_determinate_algorithms(initial_sequence)\n",
    "    if next_element is None:\n",
    "        return None\n",
    "    return sequence[-1] + next_element\n",
    "\n",
    "def apply_determinate_algorithms(sequence):\n",
    "    pr = handle_arithmetic_progression(sequence)\n",
    "    if pr is not None:\n",
    "        return pr\n",
    "    else:\n",
    "        pr = handle_geometric_progression(sequence)\n",
    "        if pr is not None:\n",
    "            return pr\n",
    "        else:\n",
    "            found_model = False\n",
    "            for q in range(2, len(sequence) // 2):\n",
    "                pr = handle_linear_recurrence(sequence, q)\n",
    "                if pr is not None:\n",
    "                    return pr\n",
    "            for order in range(1, 10):\n",
    "                pr = newton_interpolation(sequence, order)\n",
    "                if pr is not None:\n",
    "                    return pr\n",
    "            pr = handle_decimal_expansion(sequence)\n",
    "            if pr is not None:\n",
    "                return pr\n",
    "    return None\n",
    "\n",
    "def handle_markov(sequence, depth, most_possibles):\n",
    "    length = len(sequence)\n",
    "    if length >= depth:\n",
    "        prefix = tuple(sequence[(length - depth):])\n",
    "        if prefix in most_possibles:\n",
    "            return most_possibles[prefix]\n",
    "    return None\n",
    "\n",
    "def handle_linear_regression(sequence):\n",
    "    if len(sequence) < 5:\n",
    "        return (None, 0)\n",
    "    n_train = len(sequence) // 2\n",
    "    if len(sequence) >= 25:\n",
    "        n_train = 17\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    for i in range(len(sequence) - n_train):\n",
    "        y_test.append(sequence[i+n_train])\n",
    "    y_test = np.array(y_test)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    sequence = scaler.fit_transform(np.array(sequence).reshape(-1, 1)).reshape(-1)\n",
    "    for i in range(len(sequence) - n_train):\n",
    "        x_train.append(sequence[i:i+n_train])\n",
    "        y_train.append(sequence[i+n_train])\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(x_train, y_train)\n",
    "#     print('sequence', sequence[-n_train:])\n",
    "    to_pred = np.array(sequence[-n_train:]).reshape(1, -1)\n",
    "    predicted_unscaled = regressor.predict(to_pred)[0]\n",
    "    pred = round(scaler.inverse_transform(np.array([[predicted_unscaled]]))[0][0])\n",
    "    validation = [round(item) for item in scaler.inverse_transform(regressor.predict(x_train).reshape(1, -1))[0]]\n",
    "\n",
    "    sure = sum(y_test == validation)\n",
    "    sure /= len(x_train)\n",
    "    return (pred, sure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov(depth):\n",
    "    for cur_depth in range(0, depth + 1):\n",
    "        distributions = {}\n",
    "        most_possibles = {}\n",
    "        for sequence in np.hstack((sequences, test_sequences)):\n",
    "            for i in range(0, len(sequence) - cur_depth):\n",
    "                cur_tuple_prefix = tuple(sequence[i:(i + cur_depth)])\n",
    "                next_item = sequence[i + cur_depth]\n",
    "                if cur_tuple_prefix in distributions:\n",
    "                    distribution = distributions[cur_tuple_prefix]\n",
    "                    if next_item in distribution:\n",
    "                        distribution[next_item] += 1\n",
    "                    else:\n",
    "                        distribution[next_item] = 1                        \n",
    "                else:\n",
    "                    distributions[cur_tuple_prefix] = {next_item: 1}\n",
    "        for (prefix, distribution) in distributions.items():\n",
    "            most_possibles[prefix] = max(distribution.items(), key=lambda entry : entry[1])[0]\n",
    "        np.save('most_possibles{0}'.format(cur_depth), most_possibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 30\n",
    "markov(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding sequence 0\n",
      "adding sequence 10000\n",
      "adding sequence 20000\n",
      "adding sequence 30000\n",
      "adding sequence 40000\n",
      "adding sequence 50000\n",
      "adding sequence 60000\n",
      "adding sequence 70000\n",
      "adding sequence 80000\n",
      "adding sequence 90000\n",
      "adding sequence 100000\n",
      "adding sequence 110000\n",
      "adding sequence 120000\n",
      "adding sequence 130000\n",
      "adding sequence 140000\n",
      "adding sequence 150000\n",
      "adding sequence 160000\n",
      "adding sequence 170000\n",
      "adding sequence 180000\n",
      "adding sequence 190000\n",
      "adding sequence 200000\n",
      "adding sequence 210000\n",
      "adding sequence 220000\n",
      "all keys:  dict_keys([10, 3, 4, 2, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "max_value = 1000000000\n",
    "n_train = 10\n",
    "\n",
    "short_rf_regressors = {}\n",
    "short_x_trains = {}\n",
    "short_y_trains = {}\n",
    "qualities = {}\n",
    "scalers = {}\n",
    "\n",
    "train_sequences = sequences\n",
    "\n",
    "for i, sequence in enumerate(np.hstack((train_sequences, test_sequences))):\n",
    "    if i % 10000 == 0:\n",
    "        print('adding sequence', i)\n",
    "    numbers = sequence\n",
    "    if max(numbers) > max_value or min(numbers) <-max_value:\n",
    "        continue\n",
    "    if len(numbers) == 1:\n",
    "        continue\n",
    "    if len(numbers) < n_train + 1:\n",
    "        short_n_train = len(numbers) // 2\n",
    "    else:\n",
    "        short_n_train = n_train\n",
    "    if short_n_train not in short_x_trains:\n",
    "        short_x_trains[short_n_train] = []\n",
    "        short_y_trains[short_n_train] = []\n",
    "    for i in range(len(numbers) - short_n_train - 1):\n",
    "        short_x_trains[short_n_train].append(numbers[i:i + short_n_train])\n",
    "        short_y_trains[short_n_train].append(numbers[i + short_n_train])\n",
    "\n",
    "print('all keys: ', short_x_trains.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestPredictor:\n",
    "    \n",
    "    def __init__(self, n_estimators, x_train, y_train, x_test):\n",
    "        print('start init')\n",
    "        x_train_unique = np.unique(x_train)\n",
    "        print('found x train unique')\n",
    "        x_test_unique = np.unique(x_test)\n",
    "        print('found x test unique')\n",
    "        x_arr = np.concatenate((x_train_unique, x_test_unique))\n",
    "        print('concatenated')\n",
    "        x_uniques = np.unique(x_arr)\n",
    "        print('found x unique', len(x_uniques))\n",
    "        y_uniques = np.unique(y_train)\n",
    "        print('found y unique', len(y_uniques))\n",
    "        x_to_indices = {}\n",
    "        x_from_indices = {}\n",
    "        y_to_indices = {}\n",
    "        y_from_indices = {}\n",
    "        \n",
    "        n_train = len(x_train[0])\n",
    "        for i, x in enumerate(x_uniques):\n",
    "            x_to_indices[x] = i\n",
    "            x_from_indices[i] = x\n",
    "        np.save('x_to_indices{0}'.format(n_train), x_to_indices)\n",
    "        np.save('x_from_indices{0}'.format(n_train), x_from_indices)\n",
    "        for i, y in enumerate(y_uniques):\n",
    "            y_to_indices[y] = i\n",
    "            y_from_indices[i] = y\n",
    "        np.save('y_to_indices{0}'.format(n_train), y_to_indices)\n",
    "        np.save('y_from_indices{0}'.format(n_train), y_from_indices)\n",
    "        self.classifier = RandomForestClassifier(n_estimators)\n",
    "        print('finish init')\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        print('start fit')\n",
    "        self.classifier.fit(np.array(self.convert_x_to_indices(x_train)), np.array([self.convert_y_to_indices(y_train, len(x_train[0])) for y in y_train]))\n",
    "        print('finish fit')\n",
    "\n",
    "    def convert_x_to_indices(self, x_train):\n",
    "        result = []\n",
    "        x_to_indices = np.load('x_to_indices{0}.npy'.format(len(x_train[0]))).item()\n",
    "        for seq in x_train:\n",
    "            result.append([x_to_indices[x] for x in seq])\n",
    "        return np.array(result)\n",
    "        \n",
    "    def convert_y_to_indices(self, y_train, n_train):\n",
    "        result = []\n",
    "        y_to_indices = np.load('y_to_indices{0}.npy'.format(n_train)).item()\n",
    "        return np.array([y_to_indices[y] for y in y_train])\n",
    "\n",
    "    def convert_y_from_indices(self, y_train, n_train):\n",
    "        result = []\n",
    "        y_from_indices = np.load('y_from_indices{0}.npy'.format(n_train)).item()\n",
    "        return np.array([y_from_indices[y] for y in y_train])\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        print('start predict')\n",
    "        predicted = []\n",
    "        for estimator in self.classifier.estimators_:\n",
    "            cur_pred = np.array([self.convert_y_from_indices(y, len(x_test[0])) for y in estimator.predict(self.convert_x_to_indices(x_test))]).reshape(-1, 1)\n",
    "            if len(predicted) == 0:\n",
    "                predicted = cur_pred\n",
    "            else:\n",
    "                predicted = np.append(predicted, cur_pred, axis=1)\n",
    "        result = []\n",
    "        for options in predicted:\n",
    "            result.append(round(np.sum(options) / len(options)))\n",
    "        print('finish predict')\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_by_lens = {}\n",
    "for sequence in test_sequences:\n",
    "    if len(sequence) == 1:\n",
    "        cur_len = 1\n",
    "    elif len(sequence) < n_train:\n",
    "        cur_len = len(sequence) // 2\n",
    "    else:\n",
    "        cur_len = n_train\n",
    "    if cur_len not in test_by_lens:\n",
    "        test_by_lens[cur_len] = []\n",
    "    for i in range(len(sequence) - cur_len - 1):\n",
    "        test_by_lens[cur_len].append(sequence[i:i + cur_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5, 6, 7])\n",
    "arr[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting and checking quality for  10\n",
      "fitting and checking quality for  3\n",
      "fitting and checking quality for  4\n",
      "fitting and checking quality for  2\n",
      "fitting and checking quality for  5\n",
      "fitting and checking quality for  1\n"
     ]
    }
   ],
   "source": [
    "for short_n_train in short_x_trains:\n",
    "    print('fitting and checking quality for ', short_n_train)\n",
    "    cur_x_train = short_x_trains[short_n_train]\n",
    "    cur_y_train = short_y_trains[short_n_train]\n",
    "    cur_regressor = RandomForestRegressor(n_estimators=25)\n",
    "    cur_regressor.fit(cur_x_train, cur_y_train)\n",
    "    short_rf_regressors[short_n_train] = cur_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "! say 'Random Forest has learnt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_random_forest(sequence, threshold):\n",
    "    if max(sequence) > max_value or min(sequence) < -max_value:\n",
    "        return None\n",
    "    cur_n_train = 0\n",
    "    if len(sequence) == 1:\n",
    "        cur_n_train = 1\n",
    "    elif len(sequence) < n_train:\n",
    "        cur_n_train = len(sequence) // 2\n",
    "    else:\n",
    "        cur_n_train = 10\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    for i in range(len(sequence) - cur_n_train):\n",
    "        x_test.append(np.array(sequence[i:i + cur_n_train]))\n",
    "        y_test.append(sequence[i + cur_n_train])\n",
    "    if len(x_test) == 0:\n",
    "        return None\n",
    "    regressor = short_rf_regressors[cur_n_train]\n",
    "    validation = np.round(regressor.predict(x_test))\n",
    "    accuracy = sum(validation == y_test) / len(x_test)\n",
    "    if (accuracy < threshold):\n",
    "        return None\n",
    "    return round(short_rf_regressors[cur_n_train].predict(np.array(sequence[-cur_n_train:]).reshape(1, -1))[0])\n",
    "#     print(qualities[cur_n_train])\n",
    "#     if qualities[cur_n_train] >= 0.7:\n",
    "#         cur_x_test = scalers[cur_n_train].transform(np.array(sequence).reshape(-1, 1)).reshape(-1)\n",
    "#         return [round(item) for item in scaler.inverse_transform(short_rf_regressors[cur_n_train].predict(cur_x_test).reshape(1, -1))[0]]\n",
    "#     else:\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence 0\n",
      "sequence 1000\n",
      "sequence 2000\n",
      "sequence 3000\n",
      "sequence 4000\n",
      "sequence 5000\n",
      "sequence 6000\n",
      "sequence 7000\n",
      "sequence 8000\n",
      "sequence 9000\n",
      "sequence 10000\n",
      "sequence 11000\n",
      "sequence 12000\n",
      "sequence 13000\n",
      "sequence 14000\n",
      "sequence 15000\n",
      "sequence 16000\n",
      "sequence 17000\n",
      "sequence 18000\n",
      "sequence 19000\n",
      "sequence 20000\n",
      "sequence 21000\n",
      "sequence 22000\n",
      "sequence 23000\n",
      "sequence 24000\n",
      "sequence 25000\n",
      "sequence 26000\n",
      "sequence 27000\n",
      "sequence 28000\n",
      "sequence 29000\n",
      "sequence 30000\n",
      "sequence 31000\n",
      "sequence 32000\n",
      "sequence 33000\n",
      "sequence 34000\n",
      "sequence 35000\n",
      "sequence 36000\n",
      "sequence 37000\n",
      "sequence 38000\n",
      "sequence 39000\n",
      "sequence 40000\n",
      "sequence 41000\n",
      "sequence 42000\n",
      "sequence 43000\n",
      "sequence 44000\n",
      "sequence 45000\n",
      "sequence 46000\n",
      "sequence 47000\n",
      "sequence 48000\n",
      "sequence 49000\n",
      "sequence 50000\n",
      "sequence 51000\n",
      "sequence 52000\n",
      "sequence 53000\n",
      "sequence 54000\n",
      "sequence 55000\n",
      "sequence 56000\n",
      "sequence 57000\n",
      "sequence 58000\n",
      "sequence 59000\n",
      "sequence 60000\n",
      "sequence 61000\n",
      "sequence 62000\n",
      "sequence 63000\n",
      "sequence 64000\n",
      "sequence 65000\n",
      "sequence 66000\n",
      "sequence 67000\n",
      "sequence 68000\n",
      "sequence 69000\n",
      "sequence 70000\n",
      "sequence 71000\n",
      "sequence 72000\n",
      "sequence 73000\n",
      "sequence 74000\n",
      "sequence 75000\n",
      "sequence 76000\n",
      "sequence 77000\n",
      "sequence 78000\n",
      "sequence 79000\n",
      "sequence 80000\n",
      "sequence 81000\n",
      "sequence 82000\n",
      "sequence 83000\n",
      "sequence 84000\n",
      "sequence 85000\n",
      "sequence 86000\n",
      "sequence 87000\n",
      "sequence 88000\n",
      "sequence 89000\n",
      "sequence 90000\n",
      "sequence 91000\n",
      "sequence 92000\n",
      "sequence 93000\n",
      "sequence 94000\n",
      "sequence 95000\n",
      "sequence 96000\n",
      "sequence 97000\n",
      "sequence 98000\n",
      "sequence 99000\n",
      "sequence 100000\n",
      "sequence 101000\n",
      "sequence 102000\n",
      "sequence 103000\n",
      "sequence 104000\n",
      "sequence 105000\n",
      "sequence 106000\n",
      "sequence 107000\n",
      "sequence 108000\n",
      "sequence 109000\n",
      "sequence 110000\n",
      "sequence 111000\n",
      "sequence 112000\n",
      "sequence 113000\n"
     ]
    }
   ],
   "source": [
    "predicted = [None] * len(ids)\n",
    "for i, sequence in enumerate(test_sequences):\n",
    "    if i % 1000 == 0:\n",
    "        print('sequence', i)\n",
    "    predicted[i] = apply_determinate_algorithms(sequence)\n",
    "    if predicted[i] is None:\n",
    "        predicted[i] = handle_partial_sums(sequence)\n",
    "        if predicted[i] is None:\n",
    "            (pred, sure) = handle_linear_regression(sequence)\n",
    "            if sure >= 0.7:\n",
    "                predicted[i] = pred\n",
    "            if predicted[i] is None:\n",
    "                predicted[i] = handle_random_forest(sequence, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_depth 30\n",
      "cur_depth 29\n",
      "cur_depth 28\n",
      "cur_depth 27\n",
      "cur_depth 26\n",
      "cur_depth 25\n",
      "cur_depth 24\n",
      "cur_depth 23\n",
      "cur_depth 22\n",
      "cur_depth 21\n",
      "cur_depth 20\n",
      "cur_depth 19\n",
      "cur_depth 18\n",
      "cur_depth 17\n",
      "cur_depth 16\n",
      "cur_depth 15\n",
      "cur_depth 14\n",
      "cur_depth 13\n",
      "cur_depth 12\n",
      "cur_depth 11\n",
      "cur_depth 10\n",
      "cur_depth 9\n",
      "cur_depth 8\n",
      "cur_depth 7\n",
      "cur_depth 6\n",
      "cur_depth 5\n",
      "cur_depth 4\n",
      "cur_depth 3\n",
      "cur_depth 2\n",
      "cur_depth 1\n",
      "cur_depth 0\n"
     ]
    }
   ],
   "source": [
    "for cur_depth in range(depth, -1, -1):\n",
    "    print('cur_depth', cur_depth)\n",
    "    most_possibles = np.load('most_possibles{0}.npy'.format(cur_depth)).item()\n",
    "    for i, sequence in enumerate(test_sequences):\n",
    "        if predicted[i] is None:\n",
    "            predicted[i] = handle_markov(sequence, cur_depth, most_possibles)\n",
    "for i, x in enumerate(predicted):\n",
    "    if x is None:\n",
    "        predicted[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array(test_data['Id'])\n",
    "with open('submission53.csv', 'w') as f:\n",
    "    f.write('Id,Last\\n')\n",
    "    for i, x in enumerate(predicted):\n",
    "        f.write('%d,%d\\n' % (ids[i], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "! say 'You can send the result to Kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
