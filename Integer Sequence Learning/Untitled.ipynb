{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences count: 113845\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "ids = np.array(test_data['Id'])\n",
    "strs = data['Sequence']\n",
    "test_strs = test_data['Sequence']\n",
    "sequences = []\n",
    "test_sequences = []\n",
    "for line in strs:\n",
    "    sequences.append([int(i) for i in line.split(',')])\n",
    "for line in test_strs:\n",
    "    test_sequences.append([int(i) for i in line.split(',')])\n",
    "\n",
    "total = len(sequences)\n",
    "print('Total sequences count: {0}'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_property_percent(f):\n",
    "    n = 0\n",
    "    for sequence in sequences:\n",
    "        if (f(sequence)):\n",
    "            n += 1\n",
    "    return (n * 100. / total, n)\n",
    "\n",
    "def print_percentage(f):\n",
    "    percent, num = has_property_percent(f)\n",
    "    print('{0}% ({1})'.format(percent, num))\n",
    "    \n",
    "def print_sequences(f):\n",
    "    for sequence in sequences:\n",
    "        if (f(sequence)):\n",
    "            print(sequence, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_percent(condition):\n",
    "    my_dict = {}\n",
    "    for i in range(0, 100):\n",
    "        my_dict[i] = 0\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        sequence = np.array(sequence)\n",
    "        mask = condition(sequence)\n",
    "        percent_of_appr = len(sequence[mask]) * 100. / len(sequence)\n",
    "        key = int(percent_of_appr)\n",
    "        my_dict[key] += 1\n",
    "    return my_dict\n",
    "\n",
    "def plot_dict(d):\n",
    "    x = np.arange(100)\n",
    "    plt.bar(x, list(d.values()), width = [1] * len(x))\n",
    "    labels = []\n",
    "    for i in range(0, len(x)):\n",
    "        if i % 10 == 0:\n",
    "            labels.append(str(i) + '%')\n",
    "        else:\n",
    "            labels.append('')\n",
    "    plt.xticks(x, labels)\n",
    "    plt.ylabel('number of sequences')\n",
    "    plt.show()   \n",
    "    \n",
    "def explore_by_dict(condition):\n",
    "    plot_dict(create_dict_percent(condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01932452018094778% (22)\n"
     ]
    }
   ],
   "source": [
    "# 1. static\n",
    "def is_static(sequence):\n",
    "    return len(np.unique(sequence)) == 1\n",
    "\n",
    "print_percentage(is_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31534103386182966% (359)\n"
     ]
    }
   ],
   "source": [
    "# 12. арифметическая прогрессия\n",
    "def is_arithmetic_progression(sequence):\n",
    "    return len(np.unique(np.diff(sequence))) == 1\n",
    "\n",
    "print_percentage(is_arithmetic_progression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1405419649523475% (160)\n"
     ]
    }
   ],
   "source": [
    "# 13. геометрическая прогрессия\n",
    "def is_geometric_progression(sequence):\n",
    "    if (0 in sequence or len(sequence) < 2):\n",
    "        return False\n",
    "    q = sequence[1] * 1. / sequence[0]\n",
    "    for i in range(2, len(sequence)):\n",
    "        if sequence[i] * 1. / sequence[i - 1] != q:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print_percentage(is_geometric_progression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.562914488998199% (8610)\n"
     ]
    }
   ],
   "source": [
    "# 26. Содержит только однозначные числа\n",
    "def contains_only_digits(sequence):\n",
    "    unique_elements = np.unique(sequence)\n",
    "    if len(unique_elements) > 10:\n",
    "        return False\n",
    "    for x in unique_elements:\n",
    "        if x < 0 or x > 9:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print_percentage(contains_only_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_arithmetic_progression(sequence):\n",
    "    if len(sequence) <= 1:\n",
    "        return None\n",
    "    if is_arithmetic_progression(sequence):\n",
    "        last = len(sequence) - 1\n",
    "        d = sequence[last] - sequence[last - 1]\n",
    "        return sequence[last] + d    \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def handle_geometric_progression(sequence):\n",
    "    if len(sequence) <= 1:\n",
    "        return None\n",
    "    if is_geometric_progression(sequence):\n",
    "        last = len(sequence) - 1\n",
    "        r = round(sequence[last] * sequence[last] // sequence[last - 1])\n",
    "        return r\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "from numpy import linalg as la\n",
    "\n",
    "def handle_linear_recurrence(sequence, order):\n",
    "    if len(sequence) <= 2 * order:\n",
    "        return None\n",
    "    a = []\n",
    "    for i in range(0, order):\n",
    "        a.append(sequence[i:order + i])\n",
    "    b = sequence[order:2*order]\n",
    "    try:\n",
    "        c = la.solve(a, b)\n",
    "    except:\n",
    "        return None\n",
    "    for i in range(order, len(sequence) - order):\n",
    "        if np.dot(c, sequence[i:order + i]) != sequence[order + i]:\n",
    "            return None\n",
    "    return np.dot(c, sequence[-order:])\n",
    "\n",
    "def newton_interpolation(sequence, order):\n",
    "    if (len(sequence) <= order + 1):\n",
    "        return None\n",
    "    h = 1\n",
    "    \n",
    "    #count coeffs\n",
    "    div_diff_old = sequence[:order + 1].copy()\n",
    "    div_diff_new = []\n",
    "    c = [sequence[0]]\n",
    "    for i in range(0, order):\n",
    "        div_diff_new = []\n",
    "        for j in range(0, order - i):\n",
    "            div_diff_new.append(div_diff_old[j + 1] - div_diff_old[j])\n",
    "        div_diff_old = div_diff_new.copy()\n",
    "        c.append(div_diff_new[0] / np.math.factorial(i + 1))\n",
    "    if (c[len(c) - 1] == 0):\n",
    "        return None\n",
    "        \n",
    "    #check other points and predict next if everything is ok\n",
    "    for i in range(order, len(sequence) + 1):\n",
    "        next_point = 0\n",
    "        q = (i + 1 - 1) / h\n",
    "        for j in range(0, len(c)):\n",
    "            mn = 1\n",
    "            for k in range(0, j):\n",
    "                mn *= q - k\n",
    "            next_point += c[j] * mn\n",
    "        if i == len(sequence):\n",
    "            return next_point\n",
    "        if next_point != sequence[i]:\n",
    "            return None\n",
    "        \n",
    "def divide_accurately(numerator, denominator, accuracy):\n",
    "    numerator *= 10 ** (accuracy + 1)\n",
    "    fract = numerator // denominator\n",
    "    digits_after_point = []\n",
    "    while fract > 0:\n",
    "        digits_after_point.append(fract % 10)\n",
    "        fract = fract // 10\n",
    "    for i in range(len(digits_after_point), accuracy + 1):\n",
    "        digits_after_point.append(0)\n",
    "    digits_after_point = np.fliplr([np.array(digits_after_point)])[0]\n",
    "    return digits_after_point\n",
    "        \n",
    "\n",
    "def get_possible_int(sequence):\n",
    "    denominator = 0\n",
    "    mn = 1\n",
    "    eps = 0.000001\n",
    "    for x in sequence:\n",
    "        mn *= 0.1\n",
    "        denominator += mn * x\n",
    "    if np.abs((1 / denominator) - round(1 / denominator)) < eps:\n",
    "        return round(1 / denominator)\n",
    "    return None\n",
    "\n",
    "def handle_decimal_expansion(sequence):\n",
    "    if (len(sequence) <= 2):\n",
    "        return None\n",
    "    if (contains_only_digits(sequence) == False):\n",
    "        return None\n",
    "    possible_int = get_possible_int(sequence)\n",
    "    if possible_int is None:\n",
    "        return None\n",
    "    possible_float = divide_accurately(1, possible_int, len(sequence) + 2)\n",
    "    for i, x in enumerate(sequence):\n",
    "        if x != possible_float[i]:\n",
    "            return None\n",
    "    return possible_float[len(sequence)]\n",
    "\n",
    "def handle_partial_sums(sequence):\n",
    "    if len(sequence) == 0:\n",
    "        return None\n",
    "    initial_sequence = np.hstack((np.array(sequence[0]), np.diff(sequence)))\n",
    "    next_element = apply_determinate_algorithms(initial_sequence)\n",
    "    if next_element is None:\n",
    "        return None\n",
    "    return sequence[-1] + next_element\n",
    "\n",
    "def apply_determinate_algorithms(sequence):\n",
    "    pr = handle_arithmetic_progression(sequence)\n",
    "    if pr is not None:\n",
    "        return pr\n",
    "    else:\n",
    "        pr = handle_geometric_progression(sequence)\n",
    "        if pr is not None:\n",
    "            return pr\n",
    "        else:\n",
    "            found_model = False\n",
    "            for q in range(2, len(sequence) // 2):\n",
    "                pr = handle_linear_recurrence(sequence, q)\n",
    "                if pr is not None:\n",
    "                    return pr\n",
    "            for order in range(1, 10):\n",
    "                pr = newton_interpolation(sequence, order)\n",
    "                if pr is not None:\n",
    "                    return pr\n",
    "            pr = handle_decimal_expansion(sequence)\n",
    "            if pr is not None:\n",
    "                return pr\n",
    "    return None\n",
    "\n",
    "def handle_markov(sequence, depth, most_possibles):\n",
    "    length = len(sequence)\n",
    "    if length >= depth:\n",
    "        prefix = tuple(sequence[(length - depth):])\n",
    "        if prefix in most_possibles:\n",
    "            return most_possibles[prefix]\n",
    "    return None\n",
    "\n",
    "def handle_linear_regression(sequence):\n",
    "    if len(sequence) < 5:\n",
    "        return (None, 0)\n",
    "    n_train = len(sequence) // 2\n",
    "    if len(sequence) >= 25:\n",
    "        n_train = 17\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    for i in range(len(sequence) - n_train):\n",
    "        y_test.append(sequence[i+n_train])\n",
    "    y_test = np.array(y_test)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    sequence = scaler.fit_transform(np.array(sequence).reshape(-1, 1)).reshape(-1)\n",
    "    for i in range(len(sequence) - n_train):\n",
    "        x_train.append(sequence[i:i+n_train])\n",
    "        y_train.append(sequence[i+n_train])\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(x_train, y_train)\n",
    "    pred = round(scaler.inverse_transform(regressor.predict(np.array(sequence[-n_train:]).reshape(1, -1))[0])[0][0])\n",
    "    validation = [round(item) for item in scaler.inverse_transform(regressor.predict(x_train).reshape(1, -1))[0]]\n",
    "\n",
    "    sure = sum(y_test == validation)\n",
    "    sure /= len(x_train)\n",
    "    return (pred, sure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding sequence 0\n",
      "adding sequence 10000\n",
      "adding sequence 20000\n",
      "adding sequence 30000\n",
      "adding sequence 40000\n",
      "adding sequence 50000\n",
      "adding sequence 60000\n",
      "adding sequence 70000\n",
      "adding sequence 80000\n",
      "adding sequence 90000\n",
      "adding sequence 100000\n",
      "adding sequence 110000\n",
      "adding sequence 120000\n",
      "adding sequence 130000\n",
      "adding sequence 140000\n",
      "adding sequence 150000\n",
      "adding sequence 160000\n",
      "adding sequence 170000\n",
      "adding sequence 180000\n",
      "adding sequence 190000\n",
      "adding sequence 200000\n",
      "adding sequence 210000\n",
      "adding sequence 220000\n",
      "all keys:  dict_keys([10, 3, 4, 2, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "n_train = 10\n",
    "\n",
    "short_rf_regressors = {}\n",
    "short_x_trains = {}\n",
    "short_y_trains = {}\n",
    "qualities = {}\n",
    "scalers = {}\n",
    "\n",
    "train_sequences = sequences\n",
    "\n",
    "for i, sequence in enumerate(np.hstack((train_sequences, test_sequences))):\n",
    "    if i % 10000 == 0:\n",
    "        print('adding sequence', i)\n",
    "    numbers = sequence\n",
    "    if len(numbers) == 1:\n",
    "        continue\n",
    "    if len(numbers) < n_train + 1:\n",
    "        short_n_train = len(numbers) // 2\n",
    "    else:\n",
    "        short_n_train = n_train\n",
    "    if short_n_train not in short_x_trains:\n",
    "        short_x_trains[short_n_train] = []\n",
    "        short_y_trains[short_n_train] = []\n",
    "    for i in range(len(numbers) - short_n_train - 1):\n",
    "        short_x_trains[short_n_train].append(numbers[i:i + short_n_train])\n",
    "        short_y_trains[short_n_train].append(numbers[i + short_n_train])\n",
    "\n",
    "print('all keys: ', short_x_trains.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestPredictor:\n",
    "    \n",
    "    def __init__(self, n_estimators, x_train, y_train, x_test):\n",
    "        print('start init')\n",
    "        x_train_unique = np.unique(x_train)\n",
    "        print('found x train unique')\n",
    "        x_test_unique = np.unique(x_test)\n",
    "        print('found x test unique')\n",
    "        x_arr = np.concatenate((x_train_unique, x_test_unique))\n",
    "        print('concatenated')\n",
    "        x_uniques = np.unique(x_arr)\n",
    "        print('found x unique', len(x_uniques))\n",
    "        y_uniques = np.unique(y_train)\n",
    "        print('found y unique', len(y_uniques))\n",
    "        x_to_indices = {}\n",
    "        x_from_indices = {}\n",
    "        y_to_indices = {}\n",
    "        y_from_indices = {}\n",
    "        \n",
    "        n_train = len(x_train[0])\n",
    "        for i, x in enumerate(x_uniques):\n",
    "            x_to_indices[x] = i\n",
    "            x_from_indices[i] = x\n",
    "        np.save('x_to_indices{0}'.format(n_train), x_to_indices)\n",
    "        np.save('x_from_indices{0}'.format(n_train), x_from_indices)\n",
    "        for i, y in enumerate(y_uniques):\n",
    "            y_to_indices[y] = i\n",
    "            y_from_indices[i] = y\n",
    "        np.save('y_to_indices{0}'.format(n_train), y_to_indices)\n",
    "        np.save('y_from_indices{0}'.format(n_train), y_from_indices)\n",
    "        self.classifier = RandomForestClassifier(n_estimators)\n",
    "        print('finish init')\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        print('start fit')\n",
    "        self.classifier.fit(np.array(self.convert_x_to_indices(x_train)), np.array([self.convert_y_to_indices(y_train, len(x_train[0])) for y in y_train]))\n",
    "        print('finish fit')\n",
    "\n",
    "    def convert_x_to_indices(self, x_train):\n",
    "        result = []\n",
    "        x_to_indices = np.load('x_to_indices{0}.npy'.format(len(x_train[0]))).item()\n",
    "        for seq in x_train:\n",
    "            result.append([x_to_indices[x] for x in seq])\n",
    "        return np.array(result)\n",
    "        \n",
    "    def convert_y_to_indices(self, y_train, n_train):\n",
    "        result = []\n",
    "        y_to_indices = np.load('y_to_indices{0}.npy'.format(n_train)).item()\n",
    "        return np.array([y_to_indices[y] for y in y_train])\n",
    "\n",
    "    def convert_y_from_indices(self, y_train, n_train):\n",
    "        result = []\n",
    "        y_from_indices = np.load('y_from_indices{0}.npy'.format(n_train)).item()\n",
    "        return np.array([y_from_indices[y] for y in y_train])\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        print('start predict')\n",
    "        predicted = []\n",
    "        for estimator in self.classifier.estimators_:\n",
    "            cur_pred = np.array([self.convert_y_from_indices(y, len(x_test[0])) for y in estimator.predict(self.convert_x_to_indices(x_test))]).reshape(-1, 1)\n",
    "            if len(predicted) == 0:\n",
    "                predicted = cur_pred\n",
    "            else:\n",
    "                predicted = np.append(predicted, cur_pred, axis=1)\n",
    "        result = []\n",
    "        for options in predicted:\n",
    "            result.append(round(np.sum(options) / len(options)))\n",
    "        print('finish predict')\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_by_lens = {}\n",
    "for sequence in test_sequences:\n",
    "    if len(sequence) == 1:\n",
    "        cur_len = 1\n",
    "    elif len(sequence) < n_train:\n",
    "        cur_len = len(sequence) // 2\n",
    "    else:\n",
    "        cur_len = n_train\n",
    "    if cur_len not in test_by_lens:\n",
    "        test_by_lens[cur_len] = []\n",
    "    for i in range(len(sequence) - cur_len - 1):\n",
    "        test_by_lens[cur_len].append(sequence[i:i + cur_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 10, 1: 11, 2: 12, 3: 13, 4: 14, 5: 15, 6: 16, 7: 17, 8: 18, 9: 19}\n",
      "{0: 10, 1: 11, 2: 12, 3: 13, 4: 14, 5: 15, 6: 16, 7: 17, 8: 18, 9: 19}\n"
     ]
    }
   ],
   "source": [
    "x_to_indices = {}\n",
    "for i in range(10):\n",
    "    x_to_indices[i] = i + 10\n",
    "print(x_to_indices)\n",
    "np.save('x_to_indices', x_to_indices)\n",
    "x_to_indices = np.load('x_to_indices.npy').item()\n",
    "print(x_to_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting and checking quality for  10\n",
      "start init\n",
      "found x train unique\n",
      "found x test unique\n",
      "concatenated\n",
      "found x unique 847095\n",
      "found y unique 779629\n",
      "finish init\n",
      "start fit\n"
     ]
    }
   ],
   "source": [
    "for short_n_train in short_x_trains:\n",
    "    print('fitting and checking quality for ', short_n_train)\n",
    "    cur_x_train = np.array(short_x_trains[short_n_train])\n",
    "    cur_len = len(cur_x_train[0])\n",
    "    cur_y_train = np.array(short_y_trains[short_n_train])\n",
    "    cur_y_test = np.copy(cur_y_train)\n",
    "    #print(cur_x_train.shape)\n",
    "    #print(test_by_lens[short_n_train])\n",
    "    cur_regressor = RandomForestPredictor(25, cur_x_train, cur_y_train, test_by_lens[short_n_train])\n",
    "    \n",
    "    cur_regressor.fit(cur_x_train, cur_y_train)\n",
    "    short_rf_regressors[short_n_train] = cur_regressor\n",
    "    validation = cur_regressor.predict(cur_x_train)\n",
    "#     print(validation[:10])\n",
    "#     print(cur_y_test[:10])\n",
    "    qualities[short_n_train] = sum(validation == cur_y_test) / len(cur_x_train)\n",
    "    print('{0}: {1}'.format(short_n_train, qualities[short_n_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_random_forest(sequence, threshold):\n",
    "    cur_n_train = 0\n",
    "    if len(sequence) == 1:\n",
    "        cur_n_train = 1\n",
    "    elif len(sequence) < n_train:\n",
    "        cur_n_train = len(sequence) // 2\n",
    "    else:\n",
    "        cur_n_train = 10\n",
    "    print(qualities[cur_n_train])\n",
    "    if qualities[cur_n_train] >= 0.7:\n",
    "        cur_x_test = scalers[cur_n_train].transform(np.array(sequence).reshape(-1, 1)).reshape(-1)\n",
    "        return [round(item) for item in scaler.inverse_transform(short_rf_regressors[cur_n_train].predict(cur_x_test).reshape(1, -1))[0]]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = [None] * len(ids)\n",
    "for i, sequence in enumerate(test_sequences):\n",
    "    if i % 1000 == 0:\n",
    "        print('sequence', i)\n",
    "    predicted[i] = apply_determinate_algorithms(sequence)\n",
    "    if predicted[i] is None:\n",
    "        predicted[i] = handle_partial_sums(sequence)\n",
    "        if predicted[i] is None:\n",
    "            (pred, sure) = handle_linear_regression(sequence)\n",
    "            if sure >= 0.7:\n",
    "                predicted[i] = pred\n",
    "            if predicted[i] is None:\n",
    "                predicted[i] = handle_random_forest(sequence)\n",
    "                \n",
    "depth = 30\n",
    "for cur_depth in range(depth, -1, -1):\n",
    "    print('cur_depth', cur_depth)\n",
    "    most_possibles = np.load('most_possibles{0}.npy'.format(cur_depth)).item()\n",
    "    for i, sequence in enumerate(test_sequences):\n",
    "        if predicted[i] is None:\n",
    "            predicted[i] = handle_markov(sequence, cur_depth, most_possibles)\n",
    "for i, x in enumerate(predicted):\n",
    "    if x is None:\n",
    "        predicted[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array(test_data['Id'])\n",
    "with open('submission50.csv', 'w') as f:\n",
    "    f.write('Id,Last\\n')\n",
    "    for i, x in enumerate(predicted):\n",
    "        f.write('%d,%d\\n' % (ids[i], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
