{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ddzina/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Flatten, LSTM, Dropout\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sequence 0... \n",
      "Processing sequence 1... \n",
      "formed train data\n",
      "model fitted\n",
      "Predicted: 11, expected: ,257733967693. Time: 41.59799098968506\n",
      "Processing sequence 2... \n",
      "formed train data\n",
      "model fitted\n",
      "Predicted: 11, expected: ,158. Time: 29.729705810546875\n",
      "Processing sequence 3... \n",
      "formed train data\n",
      "model fitted\n",
      "Predicted: 33, expected: ,406. Time: 40.789715051651\n",
      "Processing sequence 4... \n",
      "formed train data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2cfaaddd3a61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model fitted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_sequences = test_data['Sequence']\n",
    "chars = [',', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "y_pred = [0] * len(test_sequences)\n",
    "exceptions = 0\n",
    "n_train = 100\n",
    "\n",
    "total_start = time.time()\n",
    "for (j, sequence) in enumerate(test_sequences[:20]):\n",
    "    start = time.time()\n",
    "    if j % 1 == 0:\n",
    "        print('Processing sequence {0}... '.format(j))\n",
    "    \n",
    "    try:\n",
    "        last_comma = sequence.rindex(',')\n",
    "        expected = sequence[last_comma:]\n",
    "        sequence = sequence[:last_comma]\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    if len(sequence) < 101:\n",
    "        continue\n",
    "#     numbers = sequence.split(',')\n",
    "#     if len(numbers) < 4:\n",
    "#         continue\n",
    "#     len_n_train = 10\n",
    "#     if len(numbers) < 11:\n",
    "#         len_n_train = len(numbers) // 2\n",
    "#     len_sequence = [len(item) for item in numbers]\n",
    "#     len_x_train = []\n",
    "#     len_y_train = []\n",
    "#     for i in range(len(numbers) - len_n_train - 1):\n",
    "#         len_x_train.append(numbers[i:i + len_n_train])\n",
    "#         len_y_train.append(numbers[i + len_n_train])\n",
    "#     print('formed len train data')\n",
    "#     len_x_train = np.reshape(len_x_train, (-1, len_n_train, 1))\n",
    "#     len_y_train = np_utils.to_categorical(len_y_train)\n",
    "#     len_model = Sequential()\n",
    "#     len_model.add(LSTM(4, input_shape=(len_x_train.shape[1], len_x_train.shape[2])))\n",
    "#     len_model.add(Dropout(0.2))\n",
    "#     len_model.add(Dense(len_y_train.shape[1], activation='softmax'))\n",
    "#     len_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "#     len_model.fit(len_x_train, len_y_train, epochs=20, verbose=1)    \n",
    "#     print('len model fitted')\n",
    "#     len_prob = len_model.predict(np.reshape(numbers[-len_n_train:], (1, len_n_train, 1)), verbose=1)\n",
    "#     predicted_len = np.argmax(len_prob)\n",
    "#     print('predicted_len:', predicted_len)\n",
    "    predicted_len = 2\n",
    "\n",
    "    sequence += ','\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(len(sequence) - n_train - 1):\n",
    "        x_train.append([char_to_int[char] for char in sequence[i:i + n_train]])\n",
    "        y_train.append(char_to_int[sequence[i + n_train]])\n",
    "\n",
    "    print('formed train data')\n",
    "    x_train = np.reshape(x_train, (-1, n_train, 1))\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.fit(x_train, y_train, epochs=20, verbose=0)\n",
    "    print('model fitted')\n",
    "\n",
    "    word = ''\n",
    "    seq_to_predict = [char_to_int[char] for char in sequence[-n_train:]]\n",
    "    for i in range(predicted_len):\n",
    "        try:\n",
    "            x_test = np.reshape(seq_to_predict, (1, n_train, 1))\n",
    "            prediction = model.predict(x_test, verbose=0)\n",
    "            pred_int = np.argmax(prediction)\n",
    "            pred_char = int_to_char[pred_int]\n",
    "            if pred_char == ',':\n",
    "                break\n",
    "            word += pred_char\n",
    "            seq_to_predict.append(pred_int)\n",
    "            seq_to_predict = seq_to_predict[-n_train:]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    y_pred[j] = word\n",
    "    end = time.time()\n",
    "    if j % 1 == 0:\n",
    "        print('Predicted: {0}, expected: {2}. Time: {1}'.format(word, end - start, expected))\n",
    "\n",
    "total_end = time.time()\n",
    "print('Total time: {0}'.format(total_end - total_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = pd.read_csv('train.csv')['Sequence'].values\n",
    "test_sequences = pd.read_csv('test.csv')['Sequence'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ',']\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[char_to_int[item] for item in numbers[i:i + len_n_train]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array(number):\n",
    "    arr = [0] * 11\n",
    "    arr[number] = 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_n_train = 10\n",
    "len_x_train = []\n",
    "len_y_train = []\n",
    "len_x_test = []\n",
    "len_y_test = []\n",
    "for sequence in np.hstack((train_sequences, test_sequences)):\n",
    "#     if random.random() < 0.5:\n",
    "#         continue\n",
    "    numbers_str = sequence.split(',')\n",
    "    if len(numbers_str) < 11:\n",
    "        continue\n",
    "    numbers = numbers_str\n",
    "#     for number in numbers_str:\n",
    "#         numbers.append([get_array(char_to_int[item]) for item in number])\n",
    "    for i in range(len(numbers) - len_n_train - 2):\n",
    "        len_x_train.append([len(number) for number in (numbers[i:i + len_n_train])])\n",
    "        len_y_train.append(len(numbers[i + len_n_train]))\n",
    "    len_x_test.append([len(number) for number in numbers[-len_n_train - 1:-1]])\n",
    "    len_y_test.append(len(numbers[len(numbers) - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 2, 4, 5, 7, 9, 12, 16]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_x_train = np.array(len_x_train)\n",
    "len_x_test = np.array(len_x_test)\n",
    "len_y_train = np.array(len_y_train)\n",
    "len_y_test = np.array(len_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([3]) list([5]) list([3, 5]) list([10, 9]) list([3, 2, 7, 5])\n",
      " list([4, 10, 7, 9, 8]) list([4, 3, 6, 3, 9, 5, 5])\n",
      " list([7, 2, 10, 3, 6, 9, 3, 2, 10])\n",
      " list([6, 2, 4, 3, 5, 7, 4, 9, 7, 5, 8, 7])\n",
      " list([3, 2, 9, 5, 5, 9, 8, 2, 7, 9, 6, 11, 2, 5, 9, 5])]\n"
     ]
    }
   ],
   "source": [
    "print(len_x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = GradientBoostingRegressor(n_estimators=25)\n",
    "regressor.fit(len_x_train, len_y_train)\n",
    "len_y_pred = np.array([round(length) for length in regressor.predict(len_x_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear 0.7238008494389028\n"
     ]
    }
   ],
   "source": [
    "print('linear', sum(len_y_pred == len_y_test) / len(len_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest 0.8008299563591023\n"
     ]
    }
   ],
   "source": [
    "print('random forest', sum(len_y_pred == len_y_test) / len(len_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient boosting 0.6187412328553616\n"
     ]
    }
   ],
   "source": [
    "print('gradient boosting', sum(len_y_pred == len_y_test) / len(len_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10' '18' '34' '34' '6' '26' '25' '24' '14' '13']\n"
     ]
    }
   ],
   "source": [
    "print(len_x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot cast array data from dtype('float64') to dtype('<U32') according to the rule 'safe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-dc7510855009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_x_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_y_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \"\"\"\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 241\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast array data from dtype('float64') to dtype('<U32') according to the rule 'safe'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formed train data\n"
     ]
    }
   ],
   "source": [
    "n_train = 100\n",
    "x_train = []\n",
    "y_train = []\n",
    "used_sequences = set()\n",
    "\n",
    "for (j, sequence) in enumerate(np.hstack((train_sequences, test_sequences))):\n",
    "    if len(sequence) < 101:\n",
    "        continue\n",
    "    if random.random() < 0.75:\n",
    "        continue\n",
    "    used_sequences.add(sequence)\n",
    "    sequence += ','\n",
    "    for i in range(len(sequence) - n_train - 1):\n",
    "        x_train.append([char_to_int[char] for char in sequence[i:i + n_train]])\n",
    "        y_train.append(char_to_int[sequence[i + n_train]])\n",
    "x_train = np.reshape(x_train, (-1, n_train, 1))\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "print('formed train data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4605355/4605355 [==============================] - 15030s 3ms/step - loss: 1.5617\n",
      "Epoch 2/2\n",
      "4605355/4605355 [==============================] - 13618s 3ms/step - loss: 1.4754\n",
      "model fitted\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=2, verbose=1)\n",
    "print('model fitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 1, correct: 0.\n",
      "total: 1917, correct: 192.\n",
      "total: 3207, correct: 333.\n",
      "total: 4506, correct: 476.\n",
      "total: 5147, correct: 548.\n",
      "total: 6430, correct: 680.\n",
      "total: 7078, correct: 742.\n",
      "total: 7713, correct: 806.\n",
      "total: 10208, correct: 1089.\n",
      "total: 11471, correct: 1201.\n",
      "total: 13352, correct: 1416.\n",
      "total: 14609, correct: 1548.\n",
      "total: 15254, correct: 1628.\n",
      "total: 15865, correct: 1689.\n",
      "total: 16495, correct: 1751.\n",
      "total: 17125, correct: 1828.\n",
      "total: 18334, correct: 1965.\n",
      "total: 18957, correct: 2017.\n",
      "total: 19611, correct: 2085.\n",
      "total: 20867, correct: 2247.\n",
      "total: 22129, correct: 2395.\n",
      "total: 22788, correct: 2470.\n",
      "total: 24029, correct: 2602.\n",
      "total: 24664, correct: 2655.\n",
      "total: 25268, correct: 2721.\n",
      "total: 27187, correct: 2932.\n",
      "total: 27816, correct: 3004.\n",
      "total: 28453, correct: 3070.\n",
      "total: 29736, correct: 3223.\n",
      "total: 30377, correct: 3303.\n",
      "total: 31002, correct: 3388.\n",
      "total: 32293, correct: 3530.\n",
      "total: 32931, correct: 3608.\n",
      "total: 33580, correct: 3683.\n",
      "total: 36081, correct: 3943.\n",
      "total: 36721, correct: 4010.\n",
      "total: 39888, correct: 4359.\n",
      "total: 40520, correct: 4432.\n",
      "total: 41159, correct: 4500.\n",
      "total: 41819, correct: 4580.\n",
      "total: 42453, correct: 4651.\n",
      "total: 43080, correct: 4710.\n",
      "total: 43715, correct: 4762.\n",
      "total: 45011, correct: 4886.\n",
      "total: 45655, correct: 4955.\n",
      "total: 46304, correct: 5022.\n",
      "total: 48185, correct: 5230.\n",
      "total: 50096, correct: 5427.\n",
      "total: 50740, correct: 5484.\n",
      "total: 53336, correct: 5786.\n",
      "total: 54611, correct: 5934.\n",
      "total: 55233, correct: 6003.\n",
      "total: 56507, correct: 6142.\n",
      "total: 57140, correct: 6206.\n",
      "total: 57789, correct: 6279.\n",
      "total: 58407, correct: 6352.\n",
      "total: 59055, correct: 6410.\n",
      "total: 59682, correct: 6487.\n",
      "total: 60322, correct: 6558.\n",
      "total: 61621, correct: 6694.\n",
      "total: 62247, correct: 6758.\n",
      "total: 63511, correct: 6874.\n",
      "total: 64814, correct: 7019.\n",
      "total: 66731, correct: 7230.\n",
      "total: 67376, correct: 7291.\n",
      "total: 67996, correct: 7348.\n",
      "total: 68630, correct: 7420.\n",
      "total: 69281, correct: 7494.\n",
      "total: 69932, correct: 7573.\n",
      "total: 70565, correct: 7638.\n",
      "total: 71205, correct: 7715.\n",
      "total: 71859, correct: 7789.\n",
      "total: 72407, correct: 7847.\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "for i, seq in enumerate(train_sequences):\n",
    "    if seq in used_sequences:\n",
    "        continue\n",
    "    try:\n",
    "        last_comma = seq.rindex(',') + 1\n",
    "    except:\n",
    "        continue\n",
    "    full_len = len(seq)\n",
    "    expected = [char_to_int[char] for char in seq[last_comma:]]\n",
    "    seq = seq[:last_comma]\n",
    "    if len(seq) < 101:\n",
    "        continue\n",
    "    total += 1\n",
    "    seq = [char_to_int[char] for char in seq]\n",
    "    predicted = []\n",
    "    while len(seq) < full_len:\n",
    "        predicted_int = np.argmax(model.predict(np.array(seq[-n_train:]).reshape(-1, n_train, 1)))\n",
    "        seq.append(predicted_int)\n",
    "        predicted.append(predicted_int)\n",
    "        if expected[:len(predicted)] != predicted:\n",
    "            break\n",
    "    if expected == predicted:\n",
    "        correct += 1\n",
    "    if i % 1000 == 0:\n",
    "        print('total: {0}, correct: {1}.'.format(total, correct))\n",
    "\n",
    "print('total: {0}, correct: {1}.'.format(total, correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
